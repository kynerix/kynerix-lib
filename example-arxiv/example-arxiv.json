{
  "crawlers": [
    {
      "key": "arxiv-articles",
      "project": "arxiv",
      "status": "ENABLED",
      "description": "Parses the first page of Arxiv and create contents",
      "runnable": true,
      "resourceRefs": [
        "arxiv-load-pdf"
      ],
      "stats": null,
      "script": "let contents = [];\n\nKYNERIX\n    .begin()\n    .forEach('dd div.meta', doc => {\n        // Iterate over docs\n        contents.push(\n            {\n                type: \"paper\",\n                dataset: \"arxiv\",\n                // Use selectors to extract content fields from page\n                title:   KYNERIX.selectText(\"div.list-title\", doc),\n                authors: KYNERIX.selectText(\"div.list-authors\", doc),\n                subject: KYNERIX.selectText(\"div.list-subjects\", doc)\n            }\n        )\n    })\n    .forEach('dt span a[href^=\"/pdf\"', (dt, index) => {\n        // Retrieve PDF urls\n        contents[index].pdfURL = dt.href;\n\n        // Creates content in data set\n        // and schedules a subsequent script task to load and extract the PDF content\n\n        KYNERIX.addContent(contents[index]).withScriptTask(\"arxiv-load-pdf\");\n    })\n    .assertContentCount(1, 100)\n    .end();\n\n",
      "processingTimeoutSeconds": 5,
      "loadTimeoutSeconds": 5,
      "initialURL": "https://arxiv.org/list/cs.AI/recent",
      "testURL": "https://arxiv.org/list/cs.AI/recent",
      "browserWidth": 1280,
      "browserHeight": 800,
      "type": "crawler",
      "active": true
    }
  ],
  "prompts": [
    {
      "key": "arxiv-summarize-pdf",
      "project": "arxiv",
      "status": "ENABLED",
      "description": "Creates a summary of a PDF",
      "runnable": false,
      "resourceRefs": [],
      "stats": null,
      "prompt": "Summarize the following scientific text, in plain and simple terms:\n\n{body}",
      "model": null,
      "defaultContent": {
        "key": "215",
        "status": "Summarized",
        "type": null,
        "dataset": "arxiv",
        "foundTime": null,
        "title": "A Neural Radiance Field-Based Architecture for Intelligent Multilayered View Synthesis",
        "summary": "This scientific text discusses the use of a mobile ad hoc network (MANET), which is a network of wireless portable nodes that can form a temporary network without a central management system. The text explores the challenges of routing data in a MANET and proposes a protocol called Optimized Route Selection via Red Imported Fire Ants (RIFA) to improve on-demand source routing systems. The protocol uses prediction of route failure and energy utilization to select the best path for routing. The study evaluates the protocol's performance using parameters such as energy usage, packet delivery rate, and end-to-end delay. The results show that the proposed strategy improves network lifetime, reduces node energy consumption, and decreases delay in most network performance measures. Overall, the text highlights the importance of efficient routing in MANETs and proposes a solution to enhance network performance.",
        "body": "International Journal on Recent and Innovation Trends in Computing and Communicatio n  ISSN: 2321 - 8169 Volume: 11 Issue: 9  DOI: https://doi.org/10.17762/ijritcc.v11i9.83 42  Article Received:   18   July 2023   Revised:   06   September 2023   Accepted:   21   September 2023  ___________________________________________________________________________________________________________________  259  IJRITCC | September 2023, Available @   http://www.ijritcc.org  A Neural Radiance Field - Based Architecture for  Intelligent Multilayered View Synthesis  D. Dhinakaran 1 ,   S. M. Udhaya Sankar 2 ,   G.   Elumalai 3 ,   N. Jagadish kumar 4  1 Department of Computer Science and Engineering,  Vel Tech Rangarajan Dr. Sagunthala R&D Institute of Science and Technology,  Chennai, India.  * Corresponding Author:drdhinakarand@veltech.edu.in  2 Department of Computer Science and Engineering (Cyber Security) ,  R.M.K College of Engineering and Technology,  Chennai, India .  udhaya3@gmail.com  3 Department of Electronics and Communication Engineering,  Panimalar Engineering College,  Chennai, India .  elumalaig79@gmail.com  4 Department   of Computer Science and   Business Systems ,  Sri Sairam Engineering College,  Chennai, India .  Jagadishkumar.csbs@sairam.edu .in  Abstract — A mobile ad hoc network is made up of a number of wireless portable nodes that spontaneously come together en route for estab lish  a   transitory network with no need for any central management. A mobile ad hoc network (MANET) is made up of a sizable and reaso nably  dense community of mobile nodes that travel across any terrain and rely solely on wireless interfaces for communication, not   on any well before  centralized management. Furthermore, routing be supposed to offer a method for instantly delivering data across a network bet ween any two  nodes. Finding the best packet routing from across infrastructure is the major issue, though. The p roposed protocol's major goal is to identify the  least - expensive nominal capacity acquisition that assures the transportation of realistic transport that ensures its durability in   the event of any  node failure. This study suggests the Optimized Route Selec tion via Red Imported Fire Ants (RIFA) Strategy as a way to improve on - demand  source routing systems. Predicting Route Failure and energy Utilization is used to pick the path during the routing phase. Pr oposed work assess  the results of the comparisons bas ed on performance parameters like as energy usage, packet delivery rate (PDR), and end - to - end (E2E) delay.  The outcome demonstrates that the proposed strategy is preferable and increases network lifetime while lowering node energy c onsumption and  typical E 2E delay under the majority of network performance measures and factors .  Keywords - MANET, routing, optimized route selection, network, route failure, energy utilization .  I.   INTRODUCTION  The term \"mobile ad hoc network\" refers to a wireless  connection that spontaneously forms when a number of mobile  devices communicate with one another without the aid of an  organized system. Since MANETs are spread, nodes must  cooperate with one another to   ensure the network's operations.  However, because nodes in a network are self - organized and  also   have   limited   resources,   they   might   act   greedily   or  intentionally to serve their own objectives, for as by refusing to  forward packets. Trusting in a node that   exhibits poor behavior  might result in unanticipated dangers including low network  performance, high resource usage, and attack susceptibility [1].  As a result, a trust management is required to let nodes choose  how much of many other nodes' activities th at may trust. A  trust   evaluation   framework   is   comprised   of   elements   for  knowledge gathering, calculating trust levels, and establishing  trust [2 - 4]. These components work together to create reliable  connections throughout the network. Many MANET systems  ad vocate building routes haphazardly by saturating the network  with   route   request   (RREQ)   packets.   Due   to   the   large  communication packets caused by the inundation method when  creating   connections   to   the   target   destination,   MANET  performance may suffer. Additi onally, to increase efficiency of  the network, flooding processes should indeed be judiciously  regulated by lowering the   number   of mobile nodes transmitting  RREQs [5 - 7 ]. Rapid network topology reforms introduced on  by node mobility can result in frequent l ink breaks, which add  to the network's complexity and create interruptions to the  established connections. \nInternational Journal on Recent and Innovation Trends in Computing and Communicatio n  ISSN: 2321 - 8169 Volume: 11 Issue: 9  DOI: https://doi.org/10.17762/ijritcc.v11i9.83 42  Article Received:   18   July 2023   Revised:   06   September 2023   Accepted:   21   September 2023  ___________________________________________________________________________________________________________________  260  IJRITCC | September 2023, Available @   http://www.ijritcc.org  Network performance is strongly impacted by disruption  events, which results in greater latency and congestion control  and a lower packet delivery ra tio (PDR). The need for an  efficient link fault prediction approach grows as a result of such  problems [ 8 - 10 ]. In order to preserve the paths between both  the data source and its matching destination, routing protocols  employed in MANET must typically dyna mically adjust to  different in topology [1 1 - 1 3 ]. Routing protocols created for  mobile ad hoc network are divided into three primary types  based on the transit procedure.  (i)   The   essential   characteristic   of   proactively   routing  strategies is that each node   must frequently communicate route  discovery with those other nodes, irrespective as to whether the  paths are required.  (ii) The reactive routing procedures; in these, an origin  merely searches for a path to an endpoint when it is necessary.  (iii) Hybrid ro uting protocols, which combine the positive  aspects of reactive and proactive procedures. In a dynamic  world   with   common   topological   changes,   the   hybrid   and  proactive protocols won't provide acceptable results in terms of  operating costs and memory reducin g due to their sluggish  diagnosis of and reacts to path breaks and the superfluous  transact of constant updating.  To conserve bandwidth across the network, on - demand  schemes   were   created   to   reduce   the   amount   of   control  messages sent. A route to an endpoint   is only looked up when  the subsequent protocol layers demand it. The two types of  reactive routing protocols are hop - by - hop and source - based  routing [ 14 - 17 ]. Source - based routing systems like dynamic  packet forwarding (DSR) hold the whole route to the tar get, in  contrast to hop - by - hop routing protocols, which only carry the  target and the next hop addresses in respective packet data  headers   [18] . DSR, asserts itself as a legitimate direction -  finding system with such qualities, is one of most widely  acknowl edged on - demand routing algorithms. Routing protocol  and routing information are the two primary methods used by  DSR; both of these mechanisms work when a path is in  demand. Alternative courses are, however, typically found by  inundating the network with r oute request packets that move  endlessly over the whole network [ 19 - 22 ]. Therefore, it is  important to control inundating activities only when they are  effective   and   valuable   for   the   network.   Additionally,   the  effectiveness of the network is affected by th e regular link  failures caused by node occurrences, which raises the need for  an efficient failover prediction technique .  Figure 1:   Scenario of Classic MANET System  N mobile nodes in a MANET that communicates utilizing  vertex - based wireless edges (V). A   graph G D is created when  the nodes are connected in a random - mesh topology (N; V).  The availability of V is determined by the interaction range R  and the distance d here between nodes   [23] . In Figure 1, a  typical MANET situation is shown. The neighbor nod e that  makes   up the different routing path are used by the origin to  send packets to the destination [2 4   - 2 6 ]. Since the origin and  destination   are   separated   by   a   great   distance,   multi - hop  transmission is used. We presumptively move the nodes in a  randomly , which has less of an impact on how the network  works. The assault mode is not described in this circumstance  because that article focuses on trustworthy buddy choosing.  The proposed study leverages the unique Optimized Route  Selection Via Red Imported Fi re Ants (RIFA) Approach to  improve   on - demand   resource   routing   protocols.   Predicting  Route Failure   and   Power Utilization is used to pick the path  during the routing phase .  II.   LITERATURE SURVEY  Since they are made up of mobile nodes that communicate  across wireless links without centralized supervision, ad hoc  networks are vital   to   the development of   wireless mobile  networks   [27 - 30] .   Ad - hoc   wireless   networks   immediately  inherit   the   issues   with   standard   wireless   and   mobile  networking,   such   as   maximizing   bandwidth,   improving  transmission quality, and controlling power   [31] . Due to their  multi - hop structure, presence of a fixed infrastructure, ad hoc  routing, and self - routing, ad hoc networks are also responsible  for   new   research   issues   including   Configuration   adverts,  detection, and preservation   [32 - 35] . In the Internet Protocol,  there are various standardizing initiatives underway as well as  numerous commercial and academic endeavors, in addition to a  lot of proposals on various techniques and p rotocols. \nInternational Journal on Recent and Innovation Trends in Computing and Communicatio n  ISSN: 2321 - 8169 Volume: 11 Issue: 9  DOI: https://doi.org/10.17762/ijritcc.v11i9.83 42  Article Received:   18   July 2023   Revised:   06   September 2023   Accepted:   21   September 2023  ___________________________________________________________________________________________________________________  261  IJRITCC | September 2023, Available @   http://www.ijritcc.org  For mobile   edge computing, D   Zhang et   al. [7] offer  LLECP - AOMDV, an ad hoc on - demand multi - path distance  vector   (AOMDV)   routing   protocol   based   on   connection  duration and prediction of energy consumption. Whenever the  energy of the node's cascade   underneath a fixed threshold, it  discontinues taking part in routing protocol. Choosing the path  in the phase of routing selection is based on the life span of the  network link and the path's lowest energy usage. Kacem et al.  [8] concentrate on figuring ou t the best traffic flow over the  system. The proposed protocol's major goal is to identify the  least - expensive nominal capacity expenditure that guarantees  the channeling of hypothetical traffic and assures its durability  in the event of anynode malfunctio n. Throughout this aspect,  the ant system is employed to discover a way to address the  crisis of ambiguity measures in MANET, and the Petri net is  largely utilized for navigation and recognition operations via  synchronous fuzzy transitioning strategy.  The   secure   neighborhood   selection   method   employing  recurrent incentive learning is highlighted by Sankaran et al.  [9] proposed a method for identifying node stages based upon  communication   activity   incorporates   the   advantages   of  traditional routing and clever   machine learning paradigms.  Establishing stable and safe routing and transmitting channels  to the destination requires in - depth knowledge of the nodes'  performance at all connection hop - levels. A novel Obstacle -  aware and Manoeuvrability Routing (OMAR) stra tegy was  proposed   in   paper   [10].   This   plan   uses   the   DeCasteljau  approach with a Bezier curve to detect collisions.   A   Power  reliant Migration Index forwarding method utilized to reduce  the effects of mobility of a mobile node. The route to the  destination i s selected based on which has the highest EMI  value. But they have examined a few rectangular obstructions.  In each of these categories, Rajeswari et al. [11] present a  survey to review   comparative research   of multi   -   hop routing  methods. There are also br ief analyses of significant routing  problems. This review study evaluates the characteristics of  communication algorithms and emphasizes on the taxonomy  associated with MANET. Ochola et al. [12] focuses on the  black hole assault on MANET reacting routing p rotocols has  been examined in this research (AODV and DSR). To analyze  the impact of node may be determined that AODV is preferable  in a mobility network because simulations findings forecast the  effectiveness   of   DSR   declines   more   quickly   than   the  effectiv eness of AODV whenever the velocity of the terminals  is enhanced.  Relay routed DSR is an improvement put out by Shobha  and Rajanikanth [13] to cut down on the number of RREQ and  control packets. This approach chooses the intermediate nodes  to which RREQs s hould indeed be transmitted during the  mediating   phase   based   on   the   transportation   information  gathered from the nearby nodes during flood process. However,  due to the velocity of the migrating node, leading to repeated  route explorations that add addition al overhead. In paper [14],  researchers   suggested   a   DSR - based   scheme   in   which   the  Continuous   Hopfield   Neural   Network   (CHNN)   is   used   to  determine the network link's sturdiness to obtain the path with  the   greatest   stabilization   of   the   carefully   crafted   the   d ata  transmission end to the receiver side node of the DSR protocol.  The results of the test show that CHNN - DSR performs better  than DSR in contrast. However, they did not incorporate actual  terrain characteristics into their simulations.  A unique context - a ware search navigation technique for  unorganized P2P wireless file transfer systems is presented by  Sofian et al. [15] their protocol finds relevant peers who are  sharing resources that are relevant to the client query; and (ii)  makes sure that clients wou ld be accessible by taking distinct  MANET restrictions into account. They build our approach on  the technique for ordering desires by resemblance to optimal  situation in order to take into account these all limitations when  selecting the pertinent peers. A   novel routing strategy called the  energy awareness fuzzy control router (EAFCR) algorithm is  proposed by Helen et al. [16] During the exploration process,  the proposed algorithm applies fuzzy tools to create a secure  and energy - efficient path, enhancing t he cognition of the nodes.  The fuzzy system creates a much more reliable routing by  using   the   per   hop   latency,   energy   availability,   and   signal  strength.  With   the   goal   of   enhancing   the   routing   protocol  effectiveness in MANETs, Chalew et al. [17] created and  refined the manoeuvrability routing algorithm (MARA). The  suggested system enables access points to rebroadcast or ignore  messages that have already been broadcast. The choice is made  based on the interaction among node speed, node length, and  junction ba sed on residual. To lessen the possibility of link  failure and broadcasting storm issues, these variables are taken  into account during the routing path and route reply processes.  Using   the   intensity   of   the   acknowledged   packets   and   the  preemptive DSR (PDSR ) protocol, Ramesh et al. [18] predicted  the link breakage time. In this method, the source node creates  two routes — the main route as well as the backup route —  during the process of routing. The intermediate nodes on the  alternate   path   continue   monitoring   t he   signal   received  throughout the conversation period. The intermediary node  transmits a   clear   warning   to   the   intermediate   host   if   this  emission strength falls underneath the threshold level.  The alternative route is used by the source and destination  whe n it first obtains the clear warning; whether this channel  fails as well, the origin node forwards a fresh route discovery  process. Unfortunately, since it has to conduct route changing  more   regularly   whenever   the   network   topology   shifts  frequently, PDSR r eacts slowly. To deal with node failure,  PDSR   uses   a   slow   and   expensive   link   fault   prediction ",
        "url": null,
        "properties": [
          {
            "key": "authors",
            "value": "D. Dhinakaran, S. M. Udhaya Sankar, G. Elumalai, N. Jagadish kumar"
          },
          {
            "key": "subject",
            "value": "Subjects: Networking and Internet Architecture (cs.NI); Artificial Intelligence (cs.AI)"
          },
          {
            "key": "pdfURL",
            "value": "https://arxiv.org/pdf/2311.01842"
          }
        ]
      },
      "defaultContentMap": null,
      "actions": [
        {
          "action": "UPDATE_FIELD",
          "field": "summary",
          "value": "{LAST_REPLY}"
        },
        {
          "action": "UPDATE_FIELD",
          "field": "status",
          "value": "Summarized"
        }
      ],
      "type": "prompt",
      "active": true
    }
  ],
  "triggers": [
    {
      "key": "arxiv-trigger",
      "project": "arxiv",
      "status": "ENABLED",
      "description": "Starts the process of reading the first page of arxiv, summarizing the papers and create a downloadable html report",
      "runnable": true,
      "resourceRefs": [],
      "stats": null,
      "frequency": "NEVER",
      "initialTasks": [
        {
          "type": "crawler",
          "key": "arxiv-articles",
          "stage": 0,
          "contentKey": null,
          "contentDataset": null,
          "parameters": [],
          "url": "https://arxiv.org/list/cs.AI/recent"
        },
        {
          "type": "script",
          "key": "arxiv-generate-report",
          "stage": 1,
          "contentKey": null,
          "contentDataset": null,
          "parameters": [],
          "url": null
        }
      ],
      "context": [],
      "lastStart": "2023-11-08T11:57:21.228+00:00",
      "currentExecutionID": 5,
      "dataset": "arxiv",
      "maxContents": -1,
      "maxCrawlerTasks": -1,
      "maxPromptTasks": -1,
      "type": "trigger",
      "active": true
    }
  ],
  "scripts": [
    {
      "key": "arxiv-generate-report",
      "project": "arxiv",
      "status": "ENABLED",
      "description": "Generates a report in HTML format of the latest papers",
      "runnable": true,
      "resourceRefs": [
        "arxiv-template-report"
      ],
      "stats": null,
      "script": "/*\n   Example of how to run a query against a data set, and render the results by using a template\n*/ \n\nlet dataset = KYNERIX.context(\"dataset\", \"arxiv\");  // Get dataset from context, or default value\n\nawait KYNERIX.queryDataset(dataset)                 // Run a query against the dataset\n    .withType(\"paper\")                              // Iterate over contents of type paper\n    .withStatus(\"Summarized\")                       // Only those that have been summarized\n    .searchAll(\n        // Retrieve all contents in a array - alternative: forEach()\n        (papers) => {\n\n            KYNERIX.addContent(\n                {\n                    key: \"arxiv-summary.html\",      // Use key as the file name\n                    type: \"report\",                 // Optional, set a content type\n                    dataset: dataset,               \n                    html: KYNERIX.renderTemplate(   // Renders the template\n                        \"arxiv-template-report\",\n                        {                           // Build template context with the retrieved papers\n                            papers: papers\n                        })\n                }\n            );\n        }\n    );\n\n/* \nRetrieve generated content with:\n\ncurl -s -X GET \"http://<your kynerix url>/contents/arxiv/download?content-field=html&path-field=key&type=report\" \\\n    --header \"Content-Type: application/json\" \\\n    --header \"Authorization: <your api key>\" \\\n    --output arxiv.zip\n*/\n\nKYNERIX.end();\n\n",
      "processingTimeoutSeconds": 60,
      "loadTimeoutSeconds": 1,
      "type": "script",
      "active": true
    },
    {
      "key": "arxiv-load-pdf",
      "project": "arxiv",
      "status": "ENABLED",
      "description": "Load the paper's PDF, stores its content and creates the prompt tasks.",
      "runnable": false,
      "resourceRefs": [
        "arxiv-summarize-pdf"
      ],
      "stats": null,
      "script": "let MAX_PAGES = KYNERIX.parameter(\"max-pdf-pages\", 2);\n\nlet content = KYNERIX.parameter(\"content\",\n    {   // This content is just for testing\n        \"key\": \"168\",\n        \"title\": \"Active Reasoning in an Open-World Environment\",\n        \"foundTime\": \"2023-11-06T15:47:33.230+00:00\",\n        \"dataset\": \"arxiv\",\n        \"authors\": \"Manjie Xu, Guangyuan Jiang, Wei Liang, Chi Zhang, Yixin Zhu\",\n        \"subject\": \"Subjects: Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)\",\n        \"pdfURL\": \"https://arxiv.org/pdf/2311.02018\"\n    });\n\nKYNERIX.parsePDF(content.pdfURL, MAX_PAGES, (text) => {\n\n    content.body = text;\n    content.status = \"PDF Loaded\";\n\n    KYNERIX.addContent(content).withPromptTask(\"arxiv-summarize-pdf\").end();\n})",
      "processingTimeoutSeconds": 60,
      "loadTimeoutSeconds": 1,
      "type": "script",
      "active": true
    }
  ],
  "templates": [
    {
      "key": "arxiv-template-report",
      "project": "arxiv",
      "status": "ENABLED",
      "description": "Template for the summary report",
      "runnable": false,
      "resourceRefs": [],
      "stats": null,
      "template": "<!DOCTYPE html>\n<html lang=\"en\">\n\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>Arxiv summary</title>\n    <!-- Just include Bootstrap from CDN -->\n    <link href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css\" rel=\"stylesheet\"\n        integrity=\"sha384-9ndCyUaIbzAi2FUVXJi0CjmCapSmO7SnpJef0486qhLnuZ2cdeRhO02iuK6FUUVM\" crossorigin=\"anonymous\">\n</head>\n\n<body>\n    <div class=\"container\">\n        {{#papers}}\n        <div class=\"row g-0 border rounded overflow-hidden flex-md-row mb-4 shadow-sm h-md-250 position-relative\">\n            <div class=\"col p-4 d-flex flex-column position-static\">\n                <h3>{{title}}</h3>\n                <p>{{authors}}</p>\n                <p>{{summary}}</p>\n                <p><a href=\"{{pdfURL}}\">PDF</a></p>\n            </div>\n        </div>\n        {{/papers}}\n    </div>\n</body>\n\n</html>",
      "templateType": "html",
      "defaultContent": {
        "key": null,
        "status": null,
        "type": null,
        "dataset": null,
        "foundTime": null,
        "title": null,
        "summary": null,
        "body": null,
        "url": null,
        "properties": [
          {
            "key": "papers",
            "value": "[{\"key\":\"216\",\"title\":\"DiffDub: Person-generic Visual Dubbing Using Inpainting Renderer with Diffusion Auto-encoder\",\"status\":\"PDF Loaded\",\"body\":\"DIFFDUB: PERSON-GENERIC VISUAL DUBBING USING INPAINTING RENDERER WITH DIFFUSION AUTO-ENCODER  Tao Liu 1 , Chenpeng Du 1 , Shuai Fan 2 , Feilong Chen 2 ,   † Kai Yu 1 1 MoE Key Lab of Artificial Intelligence, AI Institute, X-LANCE Lab, Shanghai Jiao Tong University  2 AISpeech Ltd, Suzhou China  ABSTRACT  Generating high-quality and person-generic visual dubbing re- mains a challenge. Recent innovation has seen the advent of a two- stage paradigm, decoupling the rendering and lip synchronization process facilitated by intermediate representation as a conduit. Still, previous methodologies rely on rough landmarks or are confined to a single speaker, thus limiting their performance. In this paper, we propose   DiffDub :   Diff usion-based   dub bing. We first craft the Dif- fusion auto-encoder by an inpainting renderer incorporating a mask to delineate editable zones and unaltered regions.   This allows for seamless filling of the lower-face region while preserving the re- maining parts. Throughout our experiments, we encountered several challenges. Primarily, the semantic encoder lacks robustness, con- stricting its ability to capture high-level features. Besides, the mod- eling ignored facial positioning, causing mouth or nose jitters across frames.   To tackle these issues, we employ versatile strategies, in- cluding data augmentation and supplementary eye guidance. More- over, we encapsulated a conformer-based reference encoder and mo- tion generator fortified by a cross-attention mechanism. This enables our model to learn person-specific textures with varying references and reduces reliance on paired audio-visual data. Our rigorous ex- periments comprehensively highlight that our ground-breaking ap- proach outpaces existing methods with considerable margins and delivers seamless, intelligible videos in person-generic and multi- lingual scenarios.  Index Terms —   Talking Face, Diffusion, Face Animation, Dub- bing  1.   INTRODUCTION  Visual dubbing [1, 2, 3], an area intrinsically linked to talking head synthesis, requires the meticulous alignment of lower-face move- ments in a source video with corresponding driving audio, while pre- serving the original identity, head pose, and background depicted in the source video. The utility of this task becomes evident when there is a need to modify or substitute the audio content with alternative audio, typically for translation purposes [4], as indicated in Figure 1. The task navigates through multiple challenges[5]: maintaining high   visual quality , ensuring   temporal consistency , and perfect- ing   lip synchronization .   Visual quality necessitates the seamless alteration of the lower facial area and a harmonious integration of the generated region with the unaltered part of the image. Temporal consistency preserves a fluid and natural motion between succes- sive video frames, preempting jitters, or abrupt transitions. Lip syn- chronization mandates effective alignment between audio and visual  † Kai Yu is the corresponding author. “L es   Vengeurs ”  (French Dubbing)  Transcript:  “The Avengers”  (English   Dubbing)  “ 复仇者 ”  ( Mandarin Chinese  Dubbing)  “ 어벤저스 ”  ( Koeran   Dubbing)  Fig. 1 .   Dubbed videos with audio in various languages .   Our method can produce seamless and intelligible videos. cues. A harmonious balance between temporal consistency and lip synchronization contributes to the intelligibility of the video[6]. Regarding visual quality, a large proportion of methods [1, 7, 3] deploy Generative Adversarial Networks (GANs) as the rendering network.   Despite this, these approaches grapple with challenges such as training instability and mode collapse [8].   The Diffusion Denoising Probabilistic Model (DDPM) [9] stands out as a proba- bilistic generative model that has notably displayed promising visual quality within the realm of talking head synthesis [10, 11, 12, 13]. The foundation of the diffusion model rests on the iterative addi- tion (diffusion process) and removal (denoising process) of noise. Despite DDPM’s considerable achievements in talking face genera- tion [10, 11, 12], progress has been limited within the sphere of vi- sual dubbing, where only the lower facial area requires modification while the rest of the image remains unaltered. This stipulation con- curs with image in-painting [14, 15], where alterations are confined to the repaired region. The modified segment must blend flawlessly with the original image to emanate a natural and coherent image. However, their primary focus on static images and an absence of consideration for temporal consistency. Concerning temporal consistency and lip synchronization, cur- rent methods [1, 16, 3] have yet to fully leverage the perks of sequence modeling or transduction methods, such as Transformer [17] or Conformer [18].   These approaches typically operate on  arXiv:2311.01811v1 [cs.CV] 3 Nov 2023 \\nSynthesized   Video  Audio   Encoder  𝑎 !  Frozen   Layers  Stage   1:   Inpainting Renderer with Diffusion Auto - encoder  Inpainting Renderer  (DDIM)  Semantic  Encoder  𝑥 !  𝑥 !  𝑥 \\\"   𝑚  𝑥 \\\"  #   =   𝑥 !   ⊙   𝑚   +   𝑥 \\\"   ⊙   ( 1   −   𝑚 )  𝑥 \\\"  #  Diffusion   Process  Denoising   Process  𝑧 $%&  𝑥 '  #   𝑥 ' ( )  #   𝑥 ' ( *  #  …   𝑥 *  #   𝑥 )  #   𝑥 !  #  Inference  Stage  (No   Aug)  Train   Stage   (Image   Aug)  𝑥 +   N  Reference  Images  Semantic  Encoder  ……  𝑎 \\\"   𝑎 #   𝑎 $ % !   𝑎 $ 𝑎 &  Motion   Generator Reference   Encoder  z )   z *   z ,   z -   z . …  z )  #   z *  #   z ,  #   z / ( )  #   z /  #  z -  #  … Cross   Attention  Inpainting   Renderer  …  Stage   2:   Video Sequence Generation  𝑥 '  (s hared )  Positional Encoding  … Fig. 2 .   Architecture of DiffDub . Our DiffDub approach upholds a two-stage paradigm encompassing   inpainting rendering with Diffusion Auto-encoder   and   video sequence generation . In the first stage, we usher in a Diffusion Auto-encoder with masked conditions to generate semantic latent codes   z   through the semantic encoder. Subsequently, during the video generation phase, the semantic latent code   z , in tandem with the audio latent code   a   derived from an extant model, is employed to generate the final videos. short audio clips, e.g., 200 ms in Wav2Lip [1].   This duration, however, might fall short for some phonemes [19], let alone their combinations. Relying on such brief audio clips introduces several challenges, including needing copious, aligned audio-visual data to achieve satisfactory results.   Moreover, this approach regularly results in lip-synced but unintelligible videos [20] that often exhibit brisk lip movements or exaggerated mouth articulations [1, 16]. To surmount these challenges and harness the potential of sequence modeling, recent strategies [21, 22, 23, 13] have devised two-stage networks composed of an audio-to-representation generator and a representation-to-video rendering network.   The generator, of- ten reliant on a transformer model, maps the audio sequence onto a representative sequence while the rendering network fabricates the final video based on this representation.   These methods, by decoupling the rendering process, successfully capture long-range dependencies. DAE-talker [13] advances this approach by exploiting semantic latent variables from Diffusion Autoencoders (Diff-AE) [24] as opposed to employing explicit structural representations like blendshapes [21, 22] or landmark coefficients [23]. Diff-AE can be viewed as a data compression or a representation learner by encod- ing an input image into a semantic latent variable and reconstructing the image from this latent space.   Building upon this capability and capitalizing on Diff-AE’s demonstrated competence in learn- ing meaningful representations,   DAE-talker achieves impressive outcomes.   However, its applicability remains confined to a single speaker, like Obama, which dampens its generalization capacity. In a bid to holistically address the aforementioned challenges, we introduce   DiffDub : a person-generic visual dubbing methodol- ogy underpinned by DDPM. This paper encapsulates several contri- butions itemized below. • We have designed a potent inpainting renderer tasked with the generation of the modifiable region under the supervision of immutable components and semantic conditioning.   This method can generate seamlessly blended lower facial regions that far surpass the capabilities of preceding methods. • We have proposed diverse strategies aimed at bolstering the robustness of the semantic encoder. These tactics enable the encoder to apprehend subtle movements and supply meticu- lous positional data for the mouth and nose regions. • By leveraging the Conformer model with cross-attention, we have successively adapted our methodology to cater to an as- sortment of references and audio sequences. This adaptation allows our model to assimilate person-specific textures while reducing reliance on paired audio-visual data. • We have performed thorough quantitative and qualitative evaluations in both few-shot and one-shot settings.   Video demos are on URL 1 .  2.   DIFFDUB FRAMEWORK 2.1.   Inpainting Renderer with Diffusion Auto-encoder  This module is responsible for inpainting rendering and latent se- mantic representation learning.   Before diving into its details, it is crucial to briefly recapitulate the noising and denoising process in- herent to vanilla diffusion [9]. Given a data distribution   x 0   ∼   q   ( x 0 ) , the noising process produces a series of latent   x 1 , . . . , x T   by adding Gaussian noise with variance at each time   t . For the denoising pro- cess, we use   N   ( μ θ   ( x t , t ) , σ t )   to model   q   ( x t-1 | x t ) .   Thus, we can train a deep neural network   p θ   to predict the mean of Gaussian noise. However, the vanilla diffusion is not controllable, and we define two guidance information for the dubbing task by segregating the full image into two segments using a lower-face mask.   The first seg- ment is the reference   x 0 , providing the information to be retained, including identity, pose, and background. The second segment is the facial motion   x f   , supplying the information for the editable region. The mask encompasses the lower facial area and can be procured through a landmark predictor [25].  1 https://liutaocode.github.io/DiffDub/ \\nOur proposed approach is comprised of a semantic encoder  z sem   =   Enc ϕ   ( x f )   and an inpainting renderer   p   ( x ′  t − 1   |   x ′  t , z sem ) . Compared to Diff-AE [24], the input of the semantic encoder is solely the facial area   x f   rather than a full image   x 0 .   We opt for this approach to ensure that the semantic encoder solely imparts facial motion information. We also incorporate image augmentation throughout the training phase to ascertain the learning of high-level features by the semantic encoder instead of trivial patterns. More- over, the noised image   x t   in Diff-AE incorporates noise added across the entire image.   In contrast, in our approach, the noise is exclusively added to the masked region, thereby maintaining the unaltered section. Distinguished from   x t , the noised image here is denoted as   x ′  t   here, as articulated in Equation 1, where the symbol  ⊙   denotes element-wise product and   m   designates a binary mask matrix: zero for the edited region and one for the unchanged part. This equation demonstrates that   m   ⊙   x 0   supplies the known pixel in the given image, and   (1   −   m )   ⊙   x t   is a masked version of   x t   for each iteration   t , providing the unknown pixel.   The architecture is depicted in the first stage of Figure 2.  x ′  t   =   m   ⊙   x 0   + (1   −   m )   ⊙   x t   (1) Furthermore, it is crucial to observe that the facial image   x f  encompasses an additional eye area, extending beyond the masked region. The inclusion of this extra eye is anchored on the reason- ing that it assists in localizing the position of the nose and mouth, thereby enhancing the stability of the nose and mouth across frames. In the DDPM’s training stage, we employ the simplified loss objective delineated in [9] and incorporate a specific mask that en- sures only the loss in the editable facial motion area is computed, as depicted in Equation 2, where   ϵ   represents the actual noise. For inference, in light of the extensive iteration steps associated with dif- fusion, we opt for the Denoising Diffusion Implicit Model (DDIM) [26]—an alternative non-Markovian noising process—as the solver to accelerate the sampling process.  L simple   =   E t,x 0 ,ϵ  h  (1   −   m )   ⊙   ( ϵ   −   ϵ θ  \\u0000 x ′  t , t, z sem  \\u0001 )   2 i  (2)  2.2.   Video Sequence Generation  This phase aims to produce person-specific synthesized videos by processing   N   reference facial images and singular driving audio. It enlists the help of a reference encoder and a motion generator based on the Conformer [18]. Unlike methods [1, 3] that restricted inputs to fixed frames, our methodology permits input lengths to vary. Incor- porating the Conformer also enables us to capture global and local facial motion interactions, a considerable leap from previous meth- ods [1, 16, 3] that only facilitated interactions of short durations. Besides, in this stage, we rely on latent codes instead of prede- fined structural representations [21, 22, 23]. The latent codes fall into two categories: the semantic latent code   z   and the audio latent code  a . The semantic encoder, which remains frozen, is tasked with ex- tracting the semantic latent code from facial images. Concurrently, the audio model, using a self-supervised approach, extracts the latent code from the driving audio. The reference encoder gleans person- specific facial texture information from   N   visual latent codes   z 1:N , and the motion generator performs a one-to-one mapping, transform- ing   T   audio latent codes   a 1:T   into the corresponding   T   visual latent codes   z ′  1:T .   Ultimately, the visual latent codes are fed into the in- painting renderer to synthesize the images. To efficiently incorporate personalized textures, we introduce a cross-attention mechanism [17], a pivot from the direct concatena- tion of the reference images [1, 3, 10]. This mechanism employs the output of the reference decoder as the query, while the audio latent codes operate as the key and value in a multi-head attention opera- tion, thus generating person-aware facial motion latent codes. To enhance the robustness of the audio encoder, we retrieve the audio latent code through a weighted sum [27] of all layers of the self-supervised models. This approach deviates from the commonly used Mel-based feature representation, thus granting added language flexibility.   Furthermore, mirroring the approach adopted in DAE- Talker [13], we use a shared   x T   for DDIM as the starting point for all images, thereby ensuring that the DDIM generates deterministic and consistent results.  3.   EXPERIMENTS 3.1.   Experimental Setups Dataset.   We utilize the HDTF dataset [28] for our experiments. The HDTF dataset is comprised of high-resolution, real-world talking head videos collected from YouTube. The dataset has a total duration of around 16 hours, partitioning 245 clips for training and 68 clips for testing, aligning with the framework in [3]. Notably, the actual tally of videos utilized in our experimental setup marginally trails the official release, owing to the unavailability of 6 online videos. As part of the preprocessing endeavor, all videos in the HDTF dataset are reformatted to a fixed resolution of   256   ×   256   pixels and stan- dardized to a frame rate of 25 frames per second (FPS).  Model Details.   Similar to Diff-AE [24], the diffusion model draws on U-Net [29] and the dimension of the semantic latent code  z sem   is 512. We employ several techniques to augment the data, in- cluding horizontal flipping, color jitter, Gaussian blur, shifting, scal- ing, and rotation. The time step   T   for DDIM is set to 20. The off-the- shelf audio encoder is a pre-trained Hubert-large model [30]. The reference frame number   N   is set to 75 (3 seconds) for few-shot ex- periments. The reference encoder and motion generator use a 2-layer and 8-layer conformer, both employing two attention heads and rel- ative positional encoding [31]. The model undergoes training for an initial four epochs in the first stage, followed by an additional 100 epochs in the second stage.  Evaluation Metric.   As for   Visual Quality (VQ) , we employ Peak Signal-to-Noise Ratio (PSNR), Structured similarity (SSIM) [32] and Learned Perceptual Image Patch Similarity (LPIPS) [33] as metrics to quantify the similarity between the generated and ground truth images.   Since masked areas vary across methods, we resize all images to an identical resolution for a fair comparison and only evaluate the lower face area. As for   Synchronization (SYNC) , We utilize lip-sync-error distance (LSE-D), lip-sync-error confidence (LSE-C) [1, 34], and landmarks distance (LMD) [2]. The LSE met- rics measure the degree of lip-sync alignment between the generated lips and the audio, while the LMD metric assesses the reconstructed shape of the lower face region relative to the ground truth.  Baseline systems.   We compare our method with several state- of-the-art person-generic methods [1, 16, 23, 13].   Wav2Lip   [1] employs an auto-encoder trained through adversarial methods.   PC- AVS   [16] introduces a pose-controllable audio-visual talking face generation method.   IP-LAP   [23] and   DAE-Talker   [13] represent two-stage methodologies.   IP-LAP employs landmark,   whereas DAE-Talker utilizes latent code. For equal comparison, adjustments are made to accommodate the nature of each method. Since PC-AVS is influenced by pose, we utilize ground-truth pose information for its evaluation.   Furthermore, due to the speaker-specific design of DAE-Talker, we engage in a retraining process on HDTF. \",\"foundTime\":\"2023-11-06T15:59:56.644+00:00\",\"dataset\":\"arxiv\",\"authors\":\"Tao Liu, Chenpeng Du, Shuai Fan, Feilong Chen, Kai Yu\",\"subject\":\"Subjects: Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)\",\"pdfURL\":\"https://arxiv.org/pdf/2311.01811\"},{\"key\":\"215\",\"title\":\"A Neural Radiance Field-Based Architecture for Intelligent Multilayered View Synthesis\",\"summary\":\"This scientific text discusses the use of a mobile ad hoc network (MANET), which is a network of wireless portable nodes that can form a temporary network without a central management system. The text explores the challenges of routing data in a MANET and proposes a protocol called Optimized Route Selection via Red Imported Fire Ants (RIFA) to improve on-demand source routing systems. The protocol uses prediction of route failure and energy utilization to select the best path for routing. The study evaluates the protocol's performance using parameters such as energy usage, packet delivery rate, and end-to-end delay. The results show that the proposed strategy improves network lifetime, reduces node energy consumption, and decreases delay in most network performance measures. Overall, the text highlights the importance of efficient routing in MANETs and proposes a solution to enhance network performance.\",\"status\":\"Summarized\",\"body\":\"International Journal on Recent and Innovation Trends in Computing and Communicatio n  ISSN: 2321 - 8169 Volume: 11 Issue: 9  DOI: https://doi.org/10.17762/ijritcc.v11i9.83 42  Article Received:   18   July 2023   Revised:   06   September 2023   Accepted:   21   September 2023  ___________________________________________________________________________________________________________________  259  IJRITCC | September 2023, Available @   http://www.ijritcc.org  A Neural Radiance Field - Based Architecture for  Intelligent Multilayered View Synthesis  D. Dhinakaran 1 ,   S. M. Udhaya Sankar 2 ,   G.   Elumalai 3 ,   N. Jagadish kumar 4  1 Department of Computer Science and Engineering,  Vel Tech Rangarajan Dr. Sagunthala R&D Institute of Science and Technology,  Chennai, India.  * Corresponding Author:drdhinakarand@veltech.edu.in  2 Department of Computer Science and Engineering (Cyber Security) ,  R.M.K College of Engineering and Technology,  Chennai, India .  udhaya3@gmail.com  3 Department of Electronics and Communication Engineering,  Panimalar Engineering College,  Chennai, India .  elumalaig79@gmail.com  4 Department   of Computer Science and   Business Systems ,  Sri Sairam Engineering College,  Chennai, India .  Jagadishkumar.csbs@sairam.edu .in  Abstract — A mobile ad hoc network is made up of a number of wireless portable nodes that spontaneously come together en route for estab lish  a   transitory network with no need for any central management. A mobile ad hoc network (MANET) is made up of a sizable and reaso nably  dense community of mobile nodes that travel across any terrain and rely solely on wireless interfaces for communication, not   on any well before  centralized management. Furthermore, routing be supposed to offer a method for instantly delivering data across a network bet ween any two  nodes. Finding the best packet routing from across infrastructure is the major issue, though. The p roposed protocol's major goal is to identify the  least - expensive nominal capacity acquisition that assures the transportation of realistic transport that ensures its durability in   the event of any  node failure. This study suggests the Optimized Route Selec tion via Red Imported Fire Ants (RIFA) Strategy as a way to improve on - demand  source routing systems. Predicting Route Failure and energy Utilization is used to pick the path during the routing phase. Pr oposed work assess  the results of the comparisons bas ed on performance parameters like as energy usage, packet delivery rate (PDR), and end - to - end (E2E) delay.  The outcome demonstrates that the proposed strategy is preferable and increases network lifetime while lowering node energy c onsumption and  typical E 2E delay under the majority of network performance measures and factors .  Keywords - MANET, routing, optimized route selection, network, route failure, energy utilization .  I.   INTRODUCTION  The term \\\"mobile ad hoc network\\\" refers to a wireless  connection that spontaneously forms when a number of mobile  devices communicate with one another without the aid of an  organized system. Since MANETs are spread, nodes must  cooperate with one another to   ensure the network's operations.  However, because nodes in a network are self - organized and  also   have   limited   resources,   they   might   act   greedily   or  intentionally to serve their own objectives, for as by refusing to  forward packets. Trusting in a node that   exhibits poor behavior  might result in unanticipated dangers including low network  performance, high resource usage, and attack susceptibility [1].  As a result, a trust management is required to let nodes choose  how much of many other nodes' activities th at may trust. A  trust   evaluation   framework   is   comprised   of   elements   for  knowledge gathering, calculating trust levels, and establishing  trust [2 - 4]. These components work together to create reliable  connections throughout the network. Many MANET systems  ad vocate building routes haphazardly by saturating the network  with   route   request   (RREQ)   packets.   Due   to   the   large  communication packets caused by the inundation method when  creating   connections   to   the   target   destination,   MANET  performance may suffer. Additi onally, to increase efficiency of  the network, flooding processes should indeed be judiciously  regulated by lowering the   number   of mobile nodes transmitting  RREQs [5 - 7 ]. Rapid network topology reforms introduced on  by node mobility can result in frequent l ink breaks, which add  to the network's complexity and create interruptions to the  established connections. \\nInternational Journal on Recent and Innovation Trends in Computing and Communicatio n  ISSN: 2321 - 8169 Volume: 11 Issue: 9  DOI: https://doi.org/10.17762/ijritcc.v11i9.83 42  Article Received:   18   July 2023   Revised:   06   September 2023   Accepted:   21   September 2023  ___________________________________________________________________________________________________________________  260  IJRITCC | September 2023, Available @   http://www.ijritcc.org  Network performance is strongly impacted by disruption  events, which results in greater latency and congestion control  and a lower packet delivery ra tio (PDR). The need for an  efficient link fault prediction approach grows as a result of such  problems [ 8 - 10 ]. In order to preserve the paths between both  the data source and its matching destination, routing protocols  employed in MANET must typically dyna mically adjust to  different in topology [1 1 - 1 3 ]. Routing protocols created for  mobile ad hoc network are divided into three primary types  based on the transit procedure.  (i)   The   essential   characteristic   of   proactively   routing  strategies is that each node   must frequently communicate route  discovery with those other nodes, irrespective as to whether the  paths are required.  (ii) The reactive routing procedures; in these, an origin  merely searches for a path to an endpoint when it is necessary.  (iii) Hybrid ro uting protocols, which combine the positive  aspects of reactive and proactive procedures. In a dynamic  world   with   common   topological   changes,   the   hybrid   and  proactive protocols won't provide acceptable results in terms of  operating costs and memory reducin g due to their sluggish  diagnosis of and reacts to path breaks and the superfluous  transact of constant updating.  To conserve bandwidth across the network, on - demand  schemes   were   created   to   reduce   the   amount   of   control  messages sent. A route to an endpoint   is only looked up when  the subsequent protocol layers demand it. The two types of  reactive routing protocols are hop - by - hop and source - based  routing [ 14 - 17 ]. Source - based routing systems like dynamic  packet forwarding (DSR) hold the whole route to the tar get, in  contrast to hop - by - hop routing protocols, which only carry the  target and the next hop addresses in respective packet data  headers   [18] . DSR, asserts itself as a legitimate direction -  finding system with such qualities, is one of most widely  acknowl edged on - demand routing algorithms. Routing protocol  and routing information are the two primary methods used by  DSR; both of these mechanisms work when a path is in  demand. Alternative courses are, however, typically found by  inundating the network with r oute request packets that move  endlessly over the whole network [ 19 - 22 ]. Therefore, it is  important to control inundating activities only when they are  effective   and   valuable   for   the   network.   Additionally,   the  effectiveness of the network is affected by th e regular link  failures caused by node occurrences, which raises the need for  an efficient failover prediction technique .  Figure 1:   Scenario of Classic MANET System  N mobile nodes in a MANET that communicates utilizing  vertex - based wireless edges (V). A   graph G D is created when  the nodes are connected in a random - mesh topology (N; V).  The availability of V is determined by the interaction range R  and the distance d here between nodes   [23] . In Figure 1, a  typical MANET situation is shown. The neighbor nod e that  makes   up the different routing path are used by the origin to  send packets to the destination [2 4   - 2 6 ]. Since the origin and  destination   are   separated   by   a   great   distance,   multi - hop  transmission is used. We presumptively move the nodes in a  randomly , which has less of an impact on how the network  works. The assault mode is not described in this circumstance  because that article focuses on trustworthy buddy choosing.  The proposed study leverages the unique Optimized Route  Selection Via Red Imported Fi re Ants (RIFA) Approach to  improve   on - demand   resource   routing   protocols.   Predicting  Route Failure   and   Power Utilization is used to pick the path  during the routing phase .  II.   LITERATURE SURVEY  Since they are made up of mobile nodes that communicate  across wireless links without centralized supervision, ad hoc  networks are vital   to   the development of   wireless mobile  networks   [27 - 30] .   Ad - hoc   wireless   networks   immediately  inherit   the   issues   with   standard   wireless   and   mobile  networking,   such   as   maximizing   bandwidth,   improving  transmission quality, and controlling power   [31] . Due to their  multi - hop structure, presence of a fixed infrastructure, ad hoc  routing, and self - routing, ad hoc networks are also responsible  for   new   research   issues   including   Configuration   adverts,  detection, and preservation   [32 - 35] . In the Internet Protocol,  there are various standardizing initiatives underway as well as  numerous commercial and academic endeavors, in addition to a  lot of proposals on various techniques and p rotocols. \\nInternational Journal on Recent and Innovation Trends in Computing and Communicatio n  ISSN: 2321 - 8169 Volume: 11 Issue: 9  DOI: https://doi.org/10.17762/ijritcc.v11i9.83 42  Article Received:   18   July 2023   Revised:   06   September 2023   Accepted:   21   September 2023  ___________________________________________________________________________________________________________________  261  IJRITCC | September 2023, Available @   http://www.ijritcc.org  For mobile   edge computing, D   Zhang et   al. [7] offer  LLECP - AOMDV, an ad hoc on - demand multi - path distance  vector   (AOMDV)   routing   protocol   based   on   connection  duration and prediction of energy consumption. Whenever the  energy of the node's cascade   underneath a fixed threshold, it  discontinues taking part in routing protocol. Choosing the path  in the phase of routing selection is based on the life span of the  network link and the path's lowest energy usage. Kacem et al.  [8] concentrate on figuring ou t the best traffic flow over the  system. The proposed protocol's major goal is to identify the  least - expensive nominal capacity expenditure that guarantees  the channeling of hypothetical traffic and assures its durability  in the event of anynode malfunctio n. Throughout this aspect,  the ant system is employed to discover a way to address the  crisis of ambiguity measures in MANET, and the Petri net is  largely utilized for navigation and recognition operations via  synchronous fuzzy transitioning strategy.  The   secure   neighborhood   selection   method   employing  recurrent incentive learning is highlighted by Sankaran et al.  [9] proposed a method for identifying node stages based upon  communication   activity   incorporates   the   advantages   of  traditional routing and clever   machine learning paradigms.  Establishing stable and safe routing and transmitting channels  to the destination requires in - depth knowledge of the nodes'  performance at all connection hop - levels. A novel Obstacle -  aware and Manoeuvrability Routing (OMAR) stra tegy was  proposed   in   paper   [10].   This   plan   uses   the   DeCasteljau  approach with a Bezier curve to detect collisions.   A   Power  reliant Migration Index forwarding method utilized to reduce  the effects of mobility of a mobile node. The route to the  destination i s selected based on which has the highest EMI  value. But they have examined a few rectangular obstructions.  In each of these categories, Rajeswari et al. [11] present a  survey to review   comparative research   of multi   -   hop routing  methods. There are also br ief analyses of significant routing  problems. This review study evaluates the characteristics of  communication algorithms and emphasizes on the taxonomy  associated with MANET. Ochola et al. [12] focuses on the  black hole assault on MANET reacting routing p rotocols has  been examined in this research (AODV and DSR). To analyze  the impact of node may be determined that AODV is preferable  in a mobility network because simulations findings forecast the  effectiveness   of   DSR   declines   more   quickly   than   the  effectiv eness of AODV whenever the velocity of the terminals  is enhanced.  Relay routed DSR is an improvement put out by Shobha  and Rajanikanth [13] to cut down on the number of RREQ and  control packets. This approach chooses the intermediate nodes  to which RREQs s hould indeed be transmitted during the  mediating   phase   based   on   the   transportation   information  gathered from the nearby nodes during flood process. However,  due to the velocity of the migrating node, leading to repeated  route explorations that add addition al overhead. In paper [14],  researchers   suggested   a   DSR - based   scheme   in   which   the  Continuous   Hopfield   Neural   Network   (CHNN)   is   used   to  determine the network link's sturdiness to obtain the path with  the   greatest   stabilization   of   the   carefully   crafted   the   d ata  transmission end to the receiver side node of the DSR protocol.  The results of the test show that CHNN - DSR performs better  than DSR in contrast. However, they did not incorporate actual  terrain characteristics into their simulations.  A unique context - a ware search navigation technique for  unorganized P2P wireless file transfer systems is presented by  Sofian et al. [15] their protocol finds relevant peers who are  sharing resources that are relevant to the client query; and (ii)  makes sure that clients wou ld be accessible by taking distinct  MANET restrictions into account. They build our approach on  the technique for ordering desires by resemblance to optimal  situation in order to take into account these all limitations when  selecting the pertinent peers. A   novel routing strategy called the  energy awareness fuzzy control router (EAFCR) algorithm is  proposed by Helen et al. [16] During the exploration process,  the proposed algorithm applies fuzzy tools to create a secure  and energy - efficient path, enhancing t he cognition of the nodes.  The fuzzy system creates a much more reliable routing by  using   the   per   hop   latency,   energy   availability,   and   signal  strength.  With   the   goal   of   enhancing   the   routing   protocol  effectiveness in MANETs, Chalew et al. [17] created and  refined the manoeuvrability routing algorithm (MARA). The  suggested system enables access points to rebroadcast or ignore  messages that have already been broadcast. The choice is made  based on the interaction among node speed, node length, and  junction ba sed on residual. To lessen the possibility of link  failure and broadcasting storm issues, these variables are taken  into account during the routing path and route reply processes.  Using   the   intensity   of   the   acknowledged   packets   and   the  preemptive DSR (PDSR ) protocol, Ramesh et al. [18] predicted  the link breakage time. In this method, the source node creates  two routes — the main route as well as the backup route —  during the process of routing. The intermediate nodes on the  alternate   path   continue   monitoring   t he   signal   received  throughout the conversation period. The intermediary node  transmits a   clear   warning   to   the   intermediate   host   if   this  emission strength falls underneath the threshold level.  The alternative route is used by the source and destination  whe n it first obtains the clear warning; whether this channel  fails as well, the origin node forwards a fresh route discovery  process. Unfortunately, since it has to conduct route changing  more   regularly   whenever   the   network   topology   shifts  frequently, PDSR r eacts slowly. To deal with node failure,  PDSR   uses   a   slow   and   expensive   link   fault   prediction \",\"foundTime\":\"2023-11-06T15:59:56.637+00:00\",\"dataset\":\"arxiv\",\"authors\":\"D. Dhinakaran, S. M. Udhaya Sankar, G. Elumalai, N. Jagadish kumar\",\"subject\":\"Subjects: Networking and Internet Architecture (cs.NI); Artificial Intelligence (cs.AI)\",\"pdfURL\":\"https://arxiv.org/pdf/2311.01842\"},{\"key\":\"214\",\"title\":\"FAME: Flexible, Scalable Analogy Mappings Engine\",\"summary\":\"The text discusses a new approach called FAME (Flexible, Scalable Analogy Mappings Engine) for computational analogy. Analogy is the ability to find similarities between different domains and transfer knowledge from one domain to another. Previous approaches to computational analogy required complex manual input, but FAME aims to simplify the input requirements.\\n\\nFAME only requires the names of entities to be mapped. It automatically extracts common-sense representations from various data sources and uses them to identify mappings between the entities. Unlike previous approaches, FAME can handle partial analogies and suggests new entities to be added. Additionally, the output of FAME is easily understandable, allowing users to see why a specific mapping was chosen.\\n\\nExperiments show that FAME achieves high accuracy in mapping analogies. It correctly maps 81.2% of classical 2x2 analogy problems and achieves 77.8% accuracy on larger problems. In fact, FAME outperforms human performance in some cases. The automatic suggestions generated by FAME also resemble those suggested by humans.\\n\\nOverall, FAME advances computational analogy by allowing for more flexible input requirements and has broader applicability. It simplifies the process of mapping analogies and provides accurate results.\",\"status\":\"Summarized\",\"body\":\"FAME: Flexible, Scalable Analogy Mappings Engine  Shahar Jacob, Chen Shani, Dafna Shahaf  The Hebrew University of Jerusalem, Israel {shahar.jacob, chenxshani, dshahaf}@cs.huji.ac.il  Abstract  Analogy is one of the core capacities of human cognition; when faced with new situations, we often transfer prior experience from other do- mains. Most work on computational analogy relies heavily on complex, manually crafted input. In this work, we relax the input require- ments, requiring only names of entities to be mapped. We automatically extract common- sense representations and use them to identify a mapping between the entities. Unlike previ- ous works, our framework can handle partial analogies and suggest new entities to be added. Moreover, our method’s output is easily inter- pretable, allowing for users to understand why a specific mapping was chosen. Experiments show that our model correctly maps   81 . 2%   of classical 2x2 analogy prob- lems (guess level= 50% ).   On larger prob- lems, it achieves   77 . 8%   accuracy (mean guess level= 13 . 1% ). In another experiment, we show our algorithm outperforms human performance, and the automatic suggestions of new entities resemble those suggested by humans. We hope this work will advance computational analogy by paving the way to more flexible, realistic input requirements, with broader applicability.  1   Introduction  One of the pinnacles of human cognition is the ability to find parallels across distant domains and transfer ideas between them. This   analogous rea- soning   process enables us to learn new information faster and solve problems based on prior experi- ence (Minsky, 1988; Hofstadter and Sander, 2013; Holyoak, 1984; PJM, 1966). The most seminal work in computational anal- ogy is Gentner’s Structure Mapping Theory (SMT) (Gentner, 1983) and its implementation, Structure Mapping Engine (SME) (Falkenhainer et al., 1989). In a nutshell, SMT assumes input from two do- mains: base and target. It maps between objects in a base domain and objects in a target domain according to common   relational structure , rather than on object attributes. For example, consider the Rutherford model of the hydrogen atom, where the atom was explained in terms of the (better-understood) solar system (Falkenhainer et al., 1989):   a planet revolving around the sun is mapped to an electron revolving around the nucleus. The mapping is due to shared  relations   between objects (revolving around, being attracted to), not object attributes (round, small). One of the main criticisms brought against SME and its follow-up work is their need for extensive hand-coded input – structured representations of both the entities and their relations (see Figure 1 for the input to the atom/solar system mapping). Chalmers et al. (1992) argued that too much hu- man creativity is required to construct this input, and the analogy is already effectively given in the representations: “A brief examination [...] shows that the discovery of the similar structure in these representations is not a difficult task. The repre- sentations have been set up in such a way that the common structure is immediately apparent. Even for a computer program, the extraction of such common structure is relatively straightforward.” Some follow-up works avoid hand-coding LISP- like representations, generating them from sketches (Forbus et al., 2011), qualitative simulators (De- hghani and Forbus, 2009), etc. However, they still require much knowledge engineering, and thus are hard to scale. Nowadays, when the web is full of in- formation about potential domains to transfer ideas from (McNeil Jr and Odón, 2013), such represen- tations do not tap into the potential of web-scale analogies for augmenting human creativity. The method with the simplest input we are aware of is Latent Relation Mapping Engine (LRME) (Turney, 2008), which requires only two lists of en- tities to be mapped. Given two entities, they search for phrases containing both in a large corpus and use them to generate simple patterns. For exam-  arXiv:2311.01860v1 [cs.CL] 3 Nov 2023 \\nFigure 1: SME representation of the Solar system/Rutherford atom. Reproduced from Falkenhainer et al. (1989).  ple, “a sun-centered solar system illustrates” gives rise to patterns such as “a X * Y illustrates”. How- ever, such patterns are extremely simple and brittle, and LRME requires exact string matches between the domains (so “revolve around” is different from “rotate around”). In this work, we develop F AME , a Flexible Anal- ogy Mapping Engine. F AME ’s input requirements are minimal, requiring only two sets of entities. We apply state-of-the-art NLP and IR techniques to automatically infer commonsense relations be- tween the entities using a variety of data sources, and construct a mapping between the domains. Im- portantly, we do not require identical phrasings of relations.   Moreover, our output is interpretable, showing how the mapping was chosen. Unlike previous works, we drop the strong   bi- jectivity   assumption and let the algorithm decide which entities to include in the mapping. Meaning, we allow for entities to remain unmapped.   Our algorithm can also generate new   suggestions   for the non-mapped entities. This paves the road to algorithms that can handle even more limited input – for example, using domain   names   (solar system, atom) as input, or just a single mapped entity pairs (e.g., turn white blood cells into policemen and see how the analogy unfolds). Our contributions are: • A novel, scalable, and interpretable approach for automatically mapping two domains based on commonsense   relational   similarities. Our algorithm handles partial mappings and sug- gests additional entities. •   We   extend   the   work   of   Romero   and Razniewski (2020) to discover salient knowl- edge about pairs of entities. •   Our model’s accuracy is   81 . 2%   on simple, 2x2 problem s(guess level= 50% ). On larger problems, it achieves   77 . 8%   perfect mappings (guess level= 13 . 1% ). In another experiment, we outperform humans ( 90%   vs.   70 . 2% ) and demonstrate that our automatic suggestions re- semble human suggestions. We release code and data. 1  2   Problem Definition  An analogy is a mapping from a base domain   B  into a target domain   T   . The mapping is based on  relations , and not object attributes. Base objects are not mapped into objects that resemble them; rather, there is a common   relational structure , and they are mapped to objects that play similar roles. We follow the formulation of Sultan and Shahaf (2022), brought here for completeness:  Entities and Relations.   Let   B   = { b 1 , ..., b n } and   T  = { t 1 , ..., t m } be two sets of entities. For example:  B   = {sun, Earth, gravity, solar system, Newton},   T  = {nucleus, electrons, electricity, atom, Faraday}. Let   R   be a set of relations. A relation is a set of ordered entity pairs with some meaning. The exact representation is purposely vague, as we do not restrict ourselves to strings, embeddings, etc. Intuitively, relations should capture notions like “revolve around”. In our example, relations between   B   and   T   in- clude the   Earth   revolve around the   Sun , like   elec- trons   orbit the   nucleus ; the   Earth   creates a force field of   gravity , similar to   electrons   creating   elec- tric force   fields; the   Sun   and the   Earth   are part of the   solar system , as the   nucleus   and   electrons   are  1 https://github.com/shaharjacob/FAME \\nB   Mapping   T  Sun   →   Nucleus Earth   →   Electrons Gravity   →   Electric force Solar system   →   Atom Newton   →   Faraday  Table 1: Illustration of a relational analogy between the solar system and the atom.  part of the   atom ;   Newton   discovered   gravity , as  Faraday   is credited with discovering   electric force . Note that relation is an asymmetric function, as the pairs are ordered; e.g., Newton discovered grav- ity, but gravity did not discover Newton. Slightly abusing notation, we denote the   set   of relations that hold between two entities   e 1 , e 2   as  R ( e 1 , e 2 )   ⊆   2 R . For example,   R ( Earth, Sun )  contains {revolve around, attracted to}, etc. For clarity, we sometimes use   R B   ,   R T   to emphasize that the entities belong to the   B ,   T   domain.  Similarity.   Let   sim   be a similarity metric between two   sets   of relations,   sim   : 2 R   ×   2 R   →   [0 ,   ∞ ) . Intuitively, when applied to singletons, we want our similarity metric to capture how relations are like each other. For example, “revolve around” is similar to “orbit” and (to a lesser degree) “spiral”. When applied to sets of relations, we want   sim  to be higher if the two sets   share many distinct  relations. For example, {revolve around, attracted to} should be more similar to {orbit, drawn into} than to {revolve around, orbit} (as the last set does not include any relation similar to attraction). In Section 3.2 we present our   sim   implementation. Given one pair from   B   and one from   T   , we de- fine similarity in terms of their relations. Since   R  is asymmetric, we consider both directions:  sim ∗ ( b 1 , b 2 , t 1 , t 2 ) =  sim ( R B   ( b 1 , b 2 ) ,   R T   ( t 1 , t 2 ))+  sim ( R B   ( b 2 , b 1 ) ,   R T   ( t 2 , t 1 ))  Objective.   Our goal is to output a mapping   M   :  B → T ∪ ⊥   such that no two   B   entities are mapped to the same   T   entity (Table 1). Mapping into   ⊥  means the entity was not mapped to any entity in the   T   domain. We look for the mapping   M ∗   that captures the best inter-domain analogical structure similarity by maximizing the relational similarity:  arg max  M  n − 1 X  j =1  n X  i = j +1  sim ∗ ( b j   , b i ,   M ( b j   ) ,   M ( b i ))  Note: if   b i   or   b j   maps to   ⊥ ,   sim ∗   is defined to be 0.  3   Analogous Matching Algorithm  We wish to find the best mapping from   B   to   T   . We first extract relations between entity pairs from the same domain (Section 3.1). Then, we compute the similarity between entity pairs that could be mapped (Section 3.2). Finally, we build the map- ping (Section 3.3).  3.1   Relation Extraction  Automatically extracting relations is a key part of our algorithm, as it eliminates the need for exten- sive manual curation of the input. We focus on  commonsense   relations (e.g., the Earth   revolves around   the Sun), as opposed to situational relations (e.g., the book is on the table). This broadly falls under open information extraction (OIE), the task of generating a structured representation of the in- formation in a text. There has been a lot of work in this area, especially attempts to automate the con- struction of commonsense datasets (Etzioni et al., 2008, 2004; Yates et al., 2007; Lenat et al., 1985; Sap et al., 2019). Given two entities, we automatically extract re- lations from multiple sources:  ConceptNet.   A commonsense dataset, containing about   1 . 5 M nodes (Liu and Singh, 2004). For each entity, we receive a list of (predicate, entity), which we filtered to match the second entity (single or plural form). The predicates serve as our relations.  Open Information Extraction.   A database auto- matically extracted from a large web corpus (Et- zioni et al., 2008). It contains over 5B triplets of the form (subject, predicate, object). We searched for a match between both entities in the (subject, object) fields, and used the predicates as our relations.  GPT-3 (text-davinci-001). 2   We used a generative pretrained large language model (LM) as a knowl- edge base in a few-shot manner (Petroni et al., 2019; Brown et al., 2020b). We input a prompt of four analogies, e.g., “Q: What are the relations be- tween gravity and Newton?, A: Newton discovered  2 GPT-3 is the only data source that is not freely available. All queries needed for this paper accumulated to less than   $50 . \",\"foundTime\":\"2023-11-06T15:59:56.630+00:00\",\"dataset\":\"arxiv\",\"authors\":\"Shahar Jacob, Chen Shani, Dafna Shahaf\",\"subject\":\"Subjects: Computation and Language (cs.CL); Artificial Intelligence (cs.AI)\",\"pdfURL\":\"https://arxiv.org/pdf/2311.01860\"},{\"key\":\"213\",\"title\":\"SortNet: Learning To Rank By a Neural-Based Sorting Algorithm\",\"status\":\"PDF Loaded\",\"body\":\"SortNet: Learning To Rank By a Neural-Based Sorting Algorithm  Leonardo Rigutini, Tiziano Papini, Marco Maggini, Franco Scarselli  Dipartimento di Ingegneria dell’Informazione via Roma 56, Siena, Italy  {rigutini,papinit,maggini,franco}@dii.unisi.it  ABSTRACT  The problem of relevance ranking consists of sorting a set of objects with respect to a given criterion.   Since users may prefer different relevance criteria, the ranking algorithms should be adaptable to the user needs. Two main approaches exist in literature for the task of learning to rank: 1) a score function, learned by examples, which evaluates the proper- ties of each object yielding an absolute relevance value that can be used to order the objects or 2) a pairwise approach, where a “preference function” is learned using pairs of ob- jects to define which one has to be ranked first.   In this paper, we present SortNet, an adaptive ranking algorithm which orders objects using a neural network as a comparator. The neural network training set provides examples of the de- sired ordering between pairs of items and it is constructed by an iterative procedure which, at each iteration, adds the most informative training examples.   Moreover, the com- parator adopts a connectionist architecture that is particu- larly suited for implementing a preference function. We also prove that such an architecture has the universal approxima- tion property and can implement a wide class of functions. Finally, the proposed algorithm is evaluated on the LETOR dataset showing promising performances in comparison with other state of the art algorithms.  1.   INTRODUCTION  The standard classification or regression tasks do not in- clude all the supervised learning problems.   Some applica- tions require to focus on other computed properties of the items, rather than values or classes. For instance, in ranking tasks, the score value assigned to each object is less impor- tant than the ordering induced on the set of items by the scores. In other cases, the main goal is to retrieve the top   k  objects without considering the ordering for the remaining items. The differences among these classes of problems in- fluences the properties of that we would like to predict, the representation of the patterns and the type of the available supervision.   For example, when an user indicates that an object is to be preferred with respect to another, or that two objects should be in the same class, he/she does not assign a value to the objects themselves. In these cases, the given examples are in the form of relationships on pairs of objects and the supervision values are the result of a pref- erence or similarity function applied on the pair of items. Two of these peculiar supervised learning tasks are   prefer- ence learning   and   learning to rank . In the machine learning literature, preference learning problems can be categorized into two specific cases, the   Learning Objects Preference   and the   Learning Labels Preference   formulations as reviewed in [7].   In the learning objects preferences scenario, it is sup- posed to have a collection of instances   x i   with associated a total or partial ordering.   The goal of the training is to learn a function that, given a pair of objects, correctly pre- dicts the associated preference as provided by the available ordering. In this approach, the training examples consist of preferences between pairwise instances, while the supervi- sion label consist of the preference expressed by the user on the given pair:   x i   ≻   x j   if   x i   is to be preferred to   x j   ,   x i   ≺   x j  vice versa.   This approach is known as   pairwise preference learning   since it is based on pairs of objects. On the other hand, the task of relevance ranking consists of sorting a set of objects with respect to a given criterion. In learning to rank, the criterion is not predefined, but it has to be adapted to the users’ needs. The two research ar- eas of preference learning and learning to rank have shown many interactions. In particular, the approach of Herbrich et al.   in [8], which is based on a binary classifier, is con- sidered the first work on preference learning and learning to rank. Recently, an increasing number of new algorithms have been proposed to learn a scoring function for ranking objects.   Freund et al.   [5] proposed RankBoost, an algo- rithm based on a collaborative filtering approach.   Burges et al.   [3] used a neural network to model the underlying ranking function (RankNet). Similarly to the approach pro- posed in this paper, it uses a gradient descent technique to optimize a probabilistic cost function, the cross entropy. The neural network is trained on pairs of training examples using a modified backpropagation algorithm.   It differs from the method proposed in this paper for the weight-sharing scheme and for the training set construction procedure. In [1], the authors use a pairwise learning approach to train a SVM model (SVMRank), while AdaRank [13] uses an AdaBoost- based scheme to learn the preference function for ranking. Finally, Zhe Cao et al.   proposed ListNet [2], that, for the first time, extends the pairwise approach to a listwise ap- proach.   In the latter approach, lists of objects are used as instances for learning.  arXiv:2311.01864v1 [cs.LG] 3 Nov 2023 \\nIn this paper we propose SortNet, a ranking algorithm that orders objects using a neural network as a “comparator”. The neural network is trained by examples to learn a compa- rison function that specifies for each pair of objects which is the preferred one. The network is embedded into a sorting algorithm to provide the ranking of a set of objects. The comparator adopts a particular neural architecture that allows us to implement the symmetries naturally present in a preference function. The approximation capability of this architecture has been studied proving that the comparator is an universal approximator and it can implement a wide class of functions.   The comparator is trained by an itera- tive procedure, which aims at selecting the most informative patterns in the training set. In particular, at each iteration, the neural network is trained only a subset of the original training set.   This subset is enlarged at each step by in- cluding the miss-classified patterns. The procedures selects the comparator that obtains the best performance on the validation set during the learning procedure. The proposed approach is evaluated using the LETOR (LEar- ning TO Rank) dataset [10], which is a standard bench- mark for the task of learning to rank. The comparison con- siders several state-of-the-art ranking algorithms, such as RankSVM [1], RankBoost [5], FRank [12], ListNet [2], and AdaRank [13].   The paper is organized as follows.   In the next section, we introduce the neural network model along with a brief mathematical description of its properties.   In Section 3, the whole SortNet algorithm based on the com- parator is defined. In Section 4, we present the experimental setup, the LETOR dataset, and some comparative experi- mental results.   Finally, in Section 5, some conclusions are drawn.  2.   THE NEURAL COMPARATOR  In the following,   S   is a set of objects described by a vector of features. We assume that a preference relationship exists between the objects and it is represented by the symbols   ≻  and   ≺ .   Thus,   x   ≻   y   means that   x   is preferred to   y   while  x   ≺   y   that   y   is preferred to   x . The purpose of the proposed method is to learn by examples the partial order specified by the preference relationship.   The main idea is that of designing a neural network   N   that processes a representation of two objects   x, y   and produces an estimate of   P   ( x   ≻   y ) and  P   ( x   ≺   y ). We will refer to the network as the “comparator”. More formally, we will have  N ≻ ( <x, y> )   ≈   P   ( x   ≻   y )  N ≺ ( <x, y> )   ≈   P   ( x   ≺   y ) ,  where   <x, y> = [ x 1 , . . . , x d , y 1 , . . . , y d ] is the concatenation of the feature vectors of objects   x, y   and   N ≻ , N ≺   denote the two network outputs. Since the neural network approx- imates a preference function, it is naturally to enforce the following constraints on the outputs:  N ≻ ( <x, y> ) =   N ≺ ( <y, x> )   .   (1) Equation (1) suggests that the outputs   N ≻   and   N ≺   must be symmetrical with respect to the order of the examples in the input pair. The comparator consists of a feedforward neural network with one hidden layer, two outputs, implementing  N ≻   and   N ≺ , respectively, and 2 d   input neurons, where   d   is the dimension of the object feature vectors (see Figure 1). Let us assume that   v x k   ,i   ( v y k   ,i ) denotes the weight of the connection from the input node   x k   ( y k   )   1   to the   i -th hidden node,   w i, ≻ ,   w i, ≺   represent the weights of the connections from the   i -th hidden to the output nodes,   b i   is the bias of  i -th hidden and   b ≻ , b ≺   are the output biases. The network  Figure 1: The comparator network architecture  architecture adopts a weight sharing mechanism in order to ensure that the constraint (1) holds. For each hidden neuron  i , a dual neuron   i ′   exists whose weights are shared with   i  according to the following schema: 1.   v x k   ,i ′   =   v y k   ,i   and   v y k   ,i ′   =   v x k   ,i   hold, i.e., the weights from   x k   , y k   to   i   are inverted in the connections to   i ′ ; 2.   w i ′ , ≻   =   w i, ≺   and   w i ′ , ≺   =   w i, ≻   hold, i.e., the weights of the connections from hidden   i   to outputs   ≻ ,   ≺   are inverted in the connections leaving from   i ′ ; 3.   b i   =   b i ′   and   b ≻   =   b ≺   hold, i.e., the biases are shared between the dual hiddens   i   and   i ′   and between the outputs   ≻   and   ≺ . In order to study the properties of the above described ar- chitecture, let us denote by   h i ( < x, y > ) the output of the  i -th hidden neuron when the network is feeded on the pair  <x, y> . Then, using the weight–sharing rule in point 1, we have  h i ( <x, y> )   =   σ   X  k  ( v x k   ,i   x k   +   v y k   ,i   y k   ) +   b i  !  =   σ   X  k  ( v x k   ,i ′   y k   +   v y k   ,i ′   x k   ) +   b i  !  =   h i ′   ( <y, x> ) where   σ   is the activation function of hidden units. Moreover, let   N ≻ ( < x, y > ) and   N ≺ ( < x, y > ) represent the network outputs. Then, by the rules in points 2 and 4, it follows  N ≻ ( <x, y> ) = =   σ    X  i,i ′  ( w i, ≻   h i ( <x, y> ) +   w i ′ , ≻   h i ′   ( <x, y> ) +   b ≻     =   σ    X  i,i ′  ( w i ′ , ≺   h i ′   ( <y, x> ) +   w i, ≺   h i ( <y, x> ) +   b ≺     =   N ≺ ( <y, x> )   ,  1 Here, with an abuse of notation,   x k   represents the node that is feeded with the   k -th feature of   x . \\nwhere we applied the fact that   h i ( <x, y > ) =   h i ′   ( <y, x> ) as shown before. Thus,   N ≻ ( <x, y> ) =   N ≺ ( <y, x> ) holds, which proves that the constraint of equation (1) is fulfilled by the network output.  Approximation capability  It has been proved that three layered networks are universal approximators [9, 6, 4]. Similarly, it can be shown that the neural comparator described in this paper can approximate up to any degree of precision most of the practically useful functions that satisfy the constraint (1). Formally, let   F   be a set of functions   f   :   R n   →   R m ,   ∥ · ∥   be a norm on   F   and  σ   be an activation function.   The universal approximation property, proved for three layered networks, states that for any function   f   ∈ F   and any real   ε >   0, there exists a net- work that implements a function   N   :   R n   →   R m   such that  ∥ f   −   N   ∥ ≤   ε   holds. Different versions of this property have been proved, according to the adopted function set   F   (e.g., the set of the continuous or the measurable functions), the norm   ∥ · ∥   (e.g., the infinity norm or a probability norm) and the activation function   σ   (e.g., a sigmoidal or a threshold ac- tivation function) [11]. The following theorem demonstrates that the network with the proposed weight sharing man- tains the universal approximation property provided that we restrict the attention to the functions that satisfy the constraint (1).  Theorem   2.1.   Let   F   be a set of functions   f   :   R 2 d   →   R 2 ,  ∥ · ∥   be a norm on   F   and   σ   be an activation function such that the corresponding three layered neural network class has the universal approximation property on   F .   Let us denote by   F   the set of the functions   k   that belongs to   F   and, for any   <x, y> , fulfill  k ≻ ( <x, y> ) =   k ≺ ( <y, x> )   (2)  where   k ≻ , k ≺ denote the two components of the outputs of   k . Then, for any function   f   ∈ F   and any real   ε >   0 , there exists a three layered neural network satisfying the weight sharing schema defined in points 1-4 such that  ∥ f   −   h ∥ ≤   ε  holds, where   h   :   R 2 d   →   R 2   is the function implemented by the neural network.  Proof.   (sketch) By the universal approximation hypothesis, there exists a three layered neural network   A   that implements a function  r   :   R 2 d   →   R 2   such   ∥   f  2   −   r ∥ ≤   ε  2   , where   f   and   ε   are the func- tion and the real of the hypothesis, respectively. Then, we can construct another network   B   that has twice the hidden nodes of   A . The indexes of hidden nodes of   B   are partitioned into pairs   i, i ′ .   The neurons with index   i   are connected to the input and to the outputs with the same weights as in  A : in other words,   B   contains   A   as a sub–network. On the other hand, the weights of the hidden neurons with index   i ′  are defined following the weight sharing rules in points 1,2, and 3. Finally, the biases of the outputs nodes in   B   are set to twice the values of the biases in   A . Notice that, by construction, the network   B   satisfies all the rules of points 1-4 and it is a good candidate to be the net- work of the thesis.   Moreover,   B   is composed by two sub– networks, the sub-network identified by the hiddens   i   and the sub–network identified by the hiddens   i ′ . Let   p 1 , p 2   rep- resent the functions that define the contribution to the out- put by the former and the latter sub-networks, respectively. Then, we can easily prove that   p 1   produces a contribution to output which is equal to   r ( <x, y> ), i.e.,   p 1  ≻ ( <x, y> ) =   r ≻ ( < x, y> ) and   p 1  ≺ ( <x, y> ) =   r ≺ ( <x, y> ). On the other hand,  p 2   has a symmetrical behaviour with respect to   r   due to the weight–sharing schema, i.e.,   p 2  ≻ ( <x, y> ) =   r ≺ ( <y, x> ) and  p 2  ≺ ( <x, y> ) =   r ≻ ( <y, x> ). Since, the output function   h   im- plemented by   B   is given by the sum of the two components, then  h ≻ ( <x, y> )   =   p 1  ≻ ( <x, y> ) +   p 2  ≻ ( <x, y> ) = =   r ≻ ( <x, y> ) +   r ≺ ( <y, x> ) = 2 r ≻ ( <x, y> )  h ≺ ( <x, y> )   =   p 1  ≺ ( <x, y> ) +   p 2  ≺ ( <x, y> ) = =   r ≺ ( <x, y> ) +   r ≻ ( <y, x> ) = 2 r ≺ ( <x, y> ) where we have used   r ≻ ( < x, y > ) =   r ≺ ( < y, x > ) that holds by definition of   r   and   f   .   Then, the thesis follows straightforwardly by  ∥ f   −   h ∥   = 2   f  2   −   h  2   = 2   f  2   −   r   ≤   ε  The training and the test phase  To train the comparator, a learning algorithm based on gra- dient descent is used.   For each pair of inputs   <x, y> , the assigned target is  t   =  \\u001A   [1 0]   if   x   ≻   y  [0 1]   if   x   ≺   y   .   (3) and the error is measured by the squared error function  E ( <x, y> ) = ( t 1   −   N ≻ ( <x, y> )) 2   + ( t 2   −   N ≺ ( <x, y> )) 2   .  After training, the comparator can be used to predict the preference relationship between any pair of objects.   For- mally, we can define   ≻ ,   ≺   by  x   ≻   y   if   N ≻ ( <x, y> )   > N ≺ ( <x, y> )  x   ≺   y   if   N ≺ ( <x, y> )   > N ≻ ( <x, y> )   .  Notice that this approach cannot ensure that the predicted relationship defines a total order, since the transitivity prop- erty may not hold Transitivity:   x   ≻   y   and   y   ≻   z   = ⇒   x   ≻   z .  However, the experimental results show that the neural net- work can easily learn the transitivity relation provided that the training set supports its validity.  3.   THE SORTING ALGORITHM  The neural comparator is employed to provide a ranking of a set of objects. In particular, the objects are ranked by a common sorting algorithm that exploits the neural network as a comparison function.   In this case, the time compu- tational cost of the ranking is mainly due to the sorting algorithm, so that the objects can be ranked in   O ( n   log   n ). \",\"foundTime\":\"2023-11-06T15:59:56.623+00:00\",\"dataset\":\"arxiv\",\"authors\":\"Leonardo Rigutini, Tiziano Papini, Marco Maggini, Franco Scarselli\",\"subject\":\"Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Information Retrieval (cs.IR)\",\"pdfURL\":\"https://arxiv.org/pdf/2311.01864\"},{\"key\":\"212\",\"title\":\"Towards Concept-Aware Large Language Models\",\"summary\":\"The text discusses the importance of concepts in human cognitive functions and the lack of research on teaching machines to understand and reason with concepts. The text proposes the development of concept-aware large language models (LLMs) to address this gap. It explores how well current LLMs capture human concepts and their structure and discusses methods to enhance LLMs with concepts. The text presents preliminary results that show the potential of concept-aware LLMs in improving predictions and matching human intuition. The ultimate goal is to enable next-generation LLMs with concepts.\",\"status\":\"Summarized\",\"body\":\"Towards Concept-Aware Large Language Models  Chen Shani ℵ , Jilles Vreeken ⋆ , Dafna Shahaf ℵ ℵ   The Hebrew University of Jerusalem, Israel  ⋆   CISPA Helmholtz Center for Information Security, Germany  ℵ   {chenxshani,dshahaf}@cs.huji.ac.il  ⋆   vreeken@cispa.de  Abstract  Concepts play a pivotal role in various human cognitive functions, including learning, reason- ing and communication. However, there is very little work on endowing machines with the abil- ity to form and reason with concepts. In par- ticular, state-of-the-art large language models (LLMs) work at the level of   tokens , not con- cepts. In this work, we analyze how well contempo- rary LLMs capture human concepts and their structure.   We then discuss ways to develop concept-aware LLMs, taking place at different stages of the pipeline. We sketch a method for  pretraining   LLMs using concepts, and also ex- plore the simpler approach that uses the output of existing LLMs. Despite its simplicity, our proof-of-concept is shown to better match hu- man intuition, as well as improve the robustness of predictions. These preliminary results under- score the promise of concept-aware LLMs.  1   Introduction  Concepts are the glue that holds our mental model of the world together. It is hard to see how any intelligent agent could do without them.   While there is no agreed-upon definition of concepts, one can think of them as the   mental representations  that enable us to identify objects and events as be- longing to certain categories, communicate about them, and comprehend new situations in terms of previous ones: when we encounter a new situa- tion (e.g., restaurant), we draw inferences about it using concepts we have already formed (“menu”, “waiter”). Concepts can be concrete (“soup”) or abstract (“tasty”). They can also be complex, e.g., “good winter beach destinations”. While there is a lively debate on their exact nature, researchers agree   con- cepts play a pivotal role in various cognitive skills   such as reasoning, categorization, learning, planning, and decision-making (Murphy, 2004). Thus, they are of interest to AI researchers wishing to endow machines with such abilities. The representation of concepts has been studied in NLP, ML, and knowledge representation (Fuma- galli and Ferrario, 2019; Davis and Marcus, 2015; Gardenfors, 2014; Speer et al., 2017), where they often view concepts as fixed, shallow structures representing some set of entities. For example, in the work on Chen et al. (2020) concepts are flat sets of context-independent entities. However, recent studies suggest concepts are more flexible and dy- namic (Gabora et al., 2008); unfortunately, AI still struggles with accounting for the creative, context- sensitive manner in which people employ concepts. In this work we focus on adding concepts to large language models (LLMs). Recently, LLMs (Yang et al., 2019; Raffel et al., 2020; Thoppilan et al., 2022; Scao et al., 2022; Zhang et al., 2023; Bubeck et al., 2023) gained immense popularity, achieving SOTA results across the board. However, they all work at the level of   tokens , not concepts. This is problematic for even the most fundamen- tal LLM task – perplexity-based   text completion . Ranking by string probability is distorted by   sur- face form competition : different tokens compete with each other, even if they represent the same concept (“mother” and “mom”) (Holtzman et al., 2021). In other words, the probability mass of a concept is distributed across many different tokens, distorting the ranking. The problem runs deeper than mere synonyms. For example, consider the sentence “I can’t get home for the holidays because of the [MASK].” The completions “snow”, “blizzard”, “weather”, and “slippery roads” are not synonyms per se, but they correspond to the same concept – bad weather leading to hazardous driving conditions – and we believe that an LLM should treat them as such. We stress that concepts are context-dependent; for example, while “snow” and “blizzard” are sim- ilar in the context of the sentence above, they  arXiv:2311.01866v1 [cs.CL] 3 Nov 2023 \\nare very different for the sentence “I love eating [MASK] cones.” 1   Thus, we cannot rely on knowl- edge bases (such WordNet (Miller, 1995)) for gen- erating static, context-free concepts to be used for training LLMs. We take the first step towards   concept-aware LLMs , exploring the following questions:  RQ1:   How well do LLMs capture concepts?  RQ2:   How well do LLMs match human organi- zation of concepts?  RQ3:   How can we enhance an LLM in terms of concepts, with or without retraining? We first show that contemporary LLMs capture human concepts to some extent, but they are still far from humans (RQ1). We then find that LLMs violate many of the principles of human concept organization, exhibiting some inconsistency (RQ2). Lastly, we explore RQ3 from two different an- gles: first, we sketch a method to pretrain concept- aware LLMs.   Next, we implement a proof-of- concept model-agnostic method to shift any off-the- shelf pretrained LLM from token- to concept-level with no further training. Our method improves both the ranking and robustness of the underlying LLM. While we present here merely a promising proof- of-concept, our underlying objective of   endowing LLMs with concepts holds tremendous promise for the next-generation of LLMs . We hope our work will spur further research, paving new roads into this exciting new territory.  2   RQ1: How well do LLMs capture concepts?  In this section, we explore to what extent LLMs grasp concepts. While concepts can be abstract and complex, here we focus on concrete and simple ones, since these are the basic building blocks of human concepts (Varela et al., 2017).  Dataset.   To probe LLM abilities, we use the 100 everyday things (ETs) dataset (Gu et al., 2022), containing natural and man-made items everyone should be familiar with (egg, dog, elevator, table, etc.). Perhaps the most basic relation between con- cepts is   TypeOf (also called   IsA ). This relation governs the hierarchical organization of concepts humans possess. For example, we all know that a sandal is a type of shoe (denoted as   TypeOf (sandal, shoe)).  1 Snow cones are shaved-ice desserts. Blizzard cones are apparently beak-shaped face masks from the 1930s.  To automatically extract   TypeOf -relations we extracted the direct hypernyms and hyponyms of the 100 ETs’ first sense using WordNet. 2   This results in data of the following form (ET in bold): •   {footwear}   ←   shoe   ←   {anklet, baby shoe, moccasin, oxford, sandal, running shoe, ...} •   {canine, domestic animal}   ←   dog   ←   {new- foundland, hunting dog, dalmatian, corgi, ...} On average, each ET had 9.5 hyponyms and 1.1 hypernyms. Note that WordNet is noisy, and some- times the first sense is not the intended one. We added a human baseline to show the data is of sat- isfactory quality.  LLM probing.   We test the concept- TypeOf   hi- erarchy of four representative LLMs: BERT-base- uncased, T5-large, GPT-davinci-003 (Legacy), and GPT-4. 3  Since   GPT-based   models   support   question- answering, we use binary questions: “Is <ET> a type of <hypernym>?”, and “Is <hyponym> a type of <ET>?” 4  BERT and T5 are not optimized for question- answering; thus, we query them as follows: “<ET> is a type of [MASK].”, and “<hyponym> is a type of [MASK].”, and search for the desired hypernym and ET respectively along the top-k completions. The LLM is correct only if the answer is within the top-k completions. 5  As a sanity check, we added a human baseline using a random sample of 100   TypeOf (ET, hyper- nym) and 100   TypeOf (hyponym, ET) questions used for querying the GPT models. To balance a bit the answer distribution, We added 20 negative examples per question type (of the form: “Is <ET> a type of <another ET’s hypernym>?”, “Is <hy- ponym> a type of <different ET>?”). The negative examples were not part of our analysis and were included to avoid annotators seeing only positive examples. We used six members of our research group for the annotation. Their mean response vari- ance is 0.18 for the hyponyms and 0.07 for the hypernyms, showing they are calibrated.  2 https://wordnet.princeton.edu/  3 We ran the GPT-4 experiments on October 2023.  4 We queried both GPT models on 200 random combina- tions of “Is <ET1> a type of <ET2>?” (“Is dishwasher a type of tent?”). It returned “yes” 0(!) times.  5 We are aware that this task is potentially harder than GPT’s. However, testing GPT as if it were a masked LLM would likely lead to sub-optimal performance.   We hence prefer to explore two different scenarios, increasing the ro- bustness of the analysis, rather than artificially leveling the playing field. \\nFigure 1: [Higher means better] LLMs concept retrieval as a function of K. For each ET, we measure how well it retrieves in its top-k completions the ET’s hypernyms (left plot) and hyponyms (right plot). Since GPT and humans answer yes/no questions, their performance does not change as a function of K.  Figure 2: [Higher means better] LLMs’ asymmetry preservation as a function of K. For each ET, we measure how well it preserves asymmetry by   not   returning the relevant item in its top-k completions (measured only using  TypeOf   relations the LLMs correctly retrieved in RQ1). We probe both for hypernyms (left plot) and for hyponyms (right plot). Since GPT supports question-answering, its performance does not change as a function of K.  Results.   We plot the accuracy (or concept retrieval, as all examples are positive), as a function of   k  for all four LLMs and humans (Figure 1). The re- sults indicate that LLMs capture concepts to some extent, but it is far from perfect and human base- line. Models achieved (at k=50) 30%-83% retrieval for the hypernyms (human baseline is 88%) and 43%-60% for the hyponyms (human baseline is 96%). Interestingly, the GPT-based models seem to grasp more general concepts better (hypernym level), whereas BERT and T5 perform better on more specific concepts (hyponym level).  3   RQ2: How well do LLMs match human organization of concepts?  In this section, we explore concept   organization . We focus on three agreed-upon organization princi- ples of the human   TypeOf   hierarchy of concepts:  asymmetry ,   transitivity , and   property inheritance . Asymmetry  TypeOf (A, B)   = ⇒ ¬   TypeOf (B, A) The human   TypeOf   relation between concepts is asymmetric; if sandals are shoes, shoes are not sandals. To measure how well an LLM preserves asymmetry we take all the   TypeOf   relations it iden- tified in RQ1 and query the   other direction .   If an LLM correctly retrieved   TypeOf (sandal, shoe), we now query for   TypeOf (shoe, sandal) using the same querying methods and LLMs. If the LLM did not retrieve this other direction – it successfully preserved the asymmetry principle. In Figure 2 we see that all four LLMs preserve \",\"foundTime\":\"2023-11-06T15:59:56.617+00:00\",\"dataset\":\"arxiv\",\"authors\":\"Chen Shani, Jilles Vreeken, Dafna Shahaf\",\"subject\":\"Subjects: Computation and Language (cs.CL); Artificial Intelligence (cs.AI)\",\"pdfURL\":\"https://arxiv.org/pdf/2311.01866\"}]"
          }
        ]
      },
      "defaultContentMap": null,
      "type": "template",
      "active": true
    }
  ],
  "importedCrawlers": 0,
  "importedPrompts": 0,
  "importedScripts": 0,
  "importedTriggers": 0,
  "importedTemplates": 0,
  "errors": [],
  "success": true
}